---
permalink: /
title: "Biography"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a PhD student at the Informatics Institute of the University of Amsterdam supervised by Efstratios Gavves an. I studied Physics at the University of Turin where I graduated cum laude and Physics at the Imperial College where I graduated with first class honours. My research focuses on the intersection of Dynamical systems and Deep Learning. My interests also lie in applied Geometry for computer vision and representation learning.

Publications
======

* ## [Learning Reversible Symplectic Dynamics](https://proceedings.mlr.press/v168/valperga22a.html)

*Time-reversal symmetry arises naturally as a structural property in many dynamical systems of interest. While the importance of hard-wiring symmetry is increasingly recognized in machine learning, to date this has eluded time-reversibility. In this paper, we propose a new neural network architecture for learning time-reversible dynamical systems from data. We focus in particular on an adaptation to symplectic systems, because of their importance in physics-informed learning.* **(oral)**

Riccardo Valperga, Kevin Webster, Dmitry Turaev, Victoria Klein, Jeroen Lamb Proceedings of The 4th Annual Learning for Dynamics and Control Conference, PMLR 168:906-916, 2022.

<img src="images/prifile.png" style="float: right; margin: 0 0 10px 10px;"/>




* ## [Learning Lie Group Symmetry Transformations with Neural Networks](https://arxiv.org/abs/2307.01583)

*The problem of detecting and quantifying the presence of symmetries in datasets is useful for model selection, generative modeling, and data analysis, amongst others. While existing methods for hard-coding transformations in neural networks require prior knowledge of the symmetries of the task at hand, this work focuses on discovering and characterising unknown symmetries present in the dataset, namely, Lie group symmetry transformations beyond the traditional ones usually considered in the field (rotation, scaling, and translation).*

Alex Gabel\*, Victoria Klein\*, Riccardo Valperga\*, Jeroen S. W. Lamb, Kevin Webster, Rick Quax Efstratios Gavves 

Proceedings of the 2 nd Annual Workshop on Topology, Algebra, and Geometry in Machine Learning (TAG-ML) at the 40th In- ternational Conference on Machine Learning

* ## [Geometric Contrastive Learning](https://openreview.net/forum?id=cE4BY5XrzR)

*Contrastive learning has been a long-standing research area due to its versatility and importance in learning representations. Recent works have shown improved results if the learned representations are constrained to be on a hy- persphere. However, this prior geometric constraint is not fully utilized during training. In this work, we propose mak- ing use of geodesic distances on the hypersphere to learn contrasts between representations.* **(oral)**

Proceedings of the 4th Visual Inductive Priors for Data-Efficient Deep Learning Workshop at ICCV 2023

Yeskendir Koishekenov, Sharvaree Vadgama\*, Riccardo Valperga\*, Erik J. Bekkers


* ## [Neural Modulation Fields for Conditional Cone Beam Neural Tomography](https://arxiv.org/abs/2307.08351)

*Conventional Computed Tomography (CT) methods require large numbers of noise-free projections for accurate density reconstructions, limiting their applicability to the more complex class of Cone Beam Geometry CT (CBCT) reconstruction. We propose a novel conditioning method where local modulations are modeled per patient as a field over the input domain through a Neural Modulation Field (NMF). The resulting Conditional Cone Beam Neural Tomography (CondCBNT) shows improved performance for both high and low numbers of available projections on noise-free and noisy data.*

Samuele Papa, David M Knigge, Riccardo Valperga, Nikita Moriakov, Miltos Kofinas, Jan-Jakob Sonke, Efstratios Gavves

